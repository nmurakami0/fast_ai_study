{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson5\n",
    "\n",
    "- [data/field.py](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)\n",
    "- [text/test/imdb.py](https://github.com/pytorch/text/blob/master/test/imdb.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fix_length: そのlengthまでpadding\n",
    "- pad_first: 先頭にpaddingするか\n",
    "- batch_first: batchのdimensionを最初に加えるか\n",
    "- sequential: tokenizeするかどうか\n",
    "  - LABELはtokenize不要だが、batch_size x 1 の次元にするためにTrueにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1:\n",
    "# set up fields (preprocessing pipelineを定義)\n",
    "TEXT = data.Field(lower=True, fix_length=500, batch_first=True, pad_first=True)\n",
    "LABEL = data.Field(sequential=True, pad_token=None, unk_token=None, batch_first=True) # vocabularyに反映されてしまうため、unkとpadをNoneに\n",
    "# \n",
    "# make splits for data\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'label': <torchtext.data.field.Field object at 0x7f2e2dc8cfd0>, 'text': <torchtext.data.field.Field object at 0x7f2e2dc8e048>}\n",
      "len(train) 25000\n",
      "vars(train[0]) {'label': ['pos'], 'text': ['master', 'cinéaste', 'alain', 'resnais', 'likes', 'to', 'work', 'with', 'those', 'actors', 'who', 'are', 'a', 'part', 'of', 'his', 'family.in', 'this', 'film', 'too', 'we', 'see', \"resnais'\", 'family', 'members', 'like', 'pierre', 'arditi,', 'sabine', 'azema,', 'andré', 'dussolier', 'and', 'fanny', 'ardant', 'dealing', 'with', 'serious', 'themes', 'like', 'death,religion,suicide,love', 'and', 'their', 'overall', 'implications', 'on', 'our', 'daily', 'lives.the', 'formal', 'nature', 'of', 'relationship', 'shared', 'by', 'these', 'people', 'is', 'evident', 'as', 'even', 'friends,', 'they', 'address', 'each', 'other', 'using', 'a', 'formal', 'you.in', '1984,while', 'making', \"l'amour\", 'à', 'mort,resnais', 'dealt', 'with', 'time,memory', 'and', 'space', 'to', 'unravel', 'the', 'mysteries', 'of', 'a', 'fundamental', 'question', 'of', 'human', 'existence', ':is', 'love', 'stronger', 'than', 'death', '?', 'it', 'was', '16', 'years', 'ago', 'in', '1968', 'that', 'resnais', 'made', 'a', 'somewhat', 'similar', 'film', 'je', \"t'aime\", 'je', \"t'aime\", 'which', 'was', 'also', 'about', 'love', 'and', 'memories.message', 'of', 'this', 'film', 'is', 'loud', 'and', 'clear', ':true', 'and', 'deep', 'love', 'can', 'even', 'put', 'science', 'to', 'shame', 'as', 'dead', 'lovers', 'regain', 'their', 'lost', 'lives', 'leaving', 'doctors', 'to', 'care', 'for', 'their', \"reputation.l'amour\", 'à', 'mort', 'is', 'like', 'a', 'game', 'which', 'is', 'not', 'at', 'all', 'didactic.it', 'is', 'a', 'film', 'in', 'which', 'the', 'musical', 'score', 'is', 'in', 'perfect', 'tandem', 'with', 'its', 'images.this', 'is', 'one', 'of', 'the', 'reasons', 'why', 'this', 'film', 'can', 'easily', 'be', 'grasped.']}\n",
      "len(test) 25000\n"
     ]
    }
   ],
   "source": [
    "# print information about the data\n",
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))\n",
    "print('vars(train[0])', vars(train[0]))\n",
    "print('len(test)', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary\n",
    "TEXT.build_vocab(train, max_size=4998) # padとunkを考慮 (オプションについてはVocabのコンストラクタを参照)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 5000\n",
      "TEXT.vocab.vectors.size() None\n"
     ]
    }
   ],
   "source": [
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors) # build_vocabのvecotrs引数に何も渡していないので、単にtermとindexの対応が得られる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that\n",
      "neg pos\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[11])\n",
    "print(LABEL.vocab.itos[0], LABEL.vocab.itos[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make iterator for splits\n",
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=512, device=0, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    1     1     1  ...     89     5     0\n",
      "    1     1     1  ...   4180   917     0\n",
      "    1     1     1  ...      0     4     0\n",
      "       ...          ⋱          ...       \n",
      "    1     1     1  ...      0    13     0\n",
      "    1     1     1  ...    249   563     0\n",
      "    1     1     1  ...      6   893     0\n",
      "[torch.cuda.LongTensor of size 512x500 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 512x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.text)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_iter, 'test': test_iter}\n",
    "dataset_sizes = {'train': len(train), 'test': len(test)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "\n",
    "- 画像と違って1次元なので、Conv1dを用いる\n",
    "- CNNのin_channelsをembeddingの各次元とする\n",
    "- 最終出力は1次元で、[0, 1]の値とする\n",
    "  - よってこれまでのsoftmaxではなくsigmoidにし、loss functionもbinary cross entropyにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "torch.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.emb = nn.Embedding(5000, 32) # 32次元のembeddingにする\n",
    "        self.conv1 = nn.Conv1d(32, 64, kernel_size=5) \n",
    "        self.bn1 = nn.BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "        # 500x32 -> 496x64 (paddingしていないので落ちる) -> 248x64 (maxpoolのkernel sizeが(2,2)のため)\n",
    "        self.fc1 = nn.Linear(15872, 100)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = x.transpose(1, 2) # N x seq_size x embedding_sizeになっているので、N x embedding_size x seq_size に変換する\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), 2)) # max_pool1dに\n",
    "        x = self.bn1(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return self.sig(x)\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    \n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler=None, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                # get the inputs\n",
    "                inputs = data.text\n",
    "                labels = data.label.float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                preds = outputs.round() # 四捨五入して予測\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds.data == labels.data) # preds.dataに変更\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            # 最も良いモデルの重みを変数に保持\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:14<00:00,  3.36it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:05,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:04<00:00, 10.66it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0016 Acc: 0.5080\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:15<00:00,  3.26it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:05,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0013 Acc: 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:04<00:00, 11.20it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0017 Acc: 0.5178\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:14<00:00,  3.38it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:05,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0013 Acc: 0.5984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:04<00:00, 11.19it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0015 Acc: 0.5640\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:14<00:00,  3.40it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:05,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0012 Acc: 0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:04<00:00, 10.89it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.6428\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:14<00:00,  3.35it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:05,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0012 Acc: 0.6698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:04<00:00, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0015 Acc: 0.6376\n",
      "\n",
      "Training complete in 1m 36s\n",
      "Best val Acc: 0.642840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove\n",
    "\n",
    "- 自前でEmbeddingを作成してもうまくいかないので、Gloveの重みを活用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "# Approach 1:\n",
    "# set up fields\n",
    "TEXT = data.Field(lower=True, fix_length=500, batch_first=True, pad_first=True)\n",
    "LABEL = data.Field(sequential=True, batch_first=True, pad_token=None, unk_token=None) # vocabularyに反映されてしまうため、unkとpadをNonenに\n",
    "\n",
    "# make splits for data\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 251639\n",
      "TEXT.vocab.vectors.size() torch.Size([251639, 300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0466  0.2132 -0.0074  ...   0.0091 -0.2099  0.0539\n",
       "          ...             ⋱             ...          \n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 251639x300]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300)) # GloVeのembeddingを使用してvocabularyを作成->各termに対応するembeddingが得られる\n",
    "LABEL.build_vocab(train)\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())\n",
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that\n",
      "neg pos\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[11])\n",
    "print(LABEL.vocab.itos[0], LABEL.vocab.itos[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make iterator for splits\n",
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=512, device=0, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_iter, 'test': test_iter}\n",
    "dataset_sizes = {'train': len(train), 'test': len(test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   2.5690e+03  5.3453e+04  8.3310e+04\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   6.5816e+04  1.3000e+01  7.1100e+02\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   1.6000e+01  2.0000e+00  2.2646e+04\n",
      "                ...                   ⋱                   ...                \n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   4.8000e+01  3.2000e+01  7.4110e+04\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   1.0800e+02  1.3000e+01  7.3049e+04\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   3.3100e+02  8.1000e+01  3.4160e+03\n",
      "[torch.cuda.LongTensor of size 512x500 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "[torch.cuda.LongTensor of size 512x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.text)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetGlove(nn.Module):\n",
    "    def __init__(self, glove_weight):\n",
    "        super(NetGlove, self).__init__()\n",
    "        self.emb = nn.Embedding(251639, 300)\n",
    "        self.emb.weight.data.copy_(glove_weight) # Gloveの重みをsetする\n",
    "        self.conv1 = nn.Conv1d(300, 600, kernel_size=5) \n",
    "        self.bn1 = nn.BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True)\n",
    "        # 500x32 -> 496x600 -> 248x600\n",
    "        self.fc1 = nn.Linear(148800, 100)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = x.transpose(1, 2) # N x seq_size x embedding_sizeになっているので、N x embedding_size x seq_size に変換する\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), 2)) # max_pool1dに\n",
    "        x = self.bn1(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return self.sig(x)\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetGlove(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    \n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:27<00:00,  1.78s/it]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0025 Acc: 0.5145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:23<00:00,  2.13it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0024 Acc: 0.5202\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:27<00:00,  1.78s/it]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0013 Acc: 0.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:22<00:00,  2.15it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0042 Acc: 0.5918\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:27<00:00,  1.78s/it]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0011 Acc: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:22<00:00,  2.17it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0037 Acc: 0.5961\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:26<00:00,  1.77s/it]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0008 Acc: 0.7806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:22<00:00,  2.16it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0028 Acc: 0.6642\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:27<00:00,  1.78s/it]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0006 Acc: 0.8622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:22<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0021 Acc: 0.7275\n",
      "\n",
      "Training complete in 9m 10s\n",
      "Best val Acc: 0.727480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "[A Tutorial on Torchtext](http://anie.me/On-Torchtext/)\n",
    "\n",
    "- variable lengthの入力を作成\n",
    "  - padding済みから作成: torch.nn.utils.rnn.pack_padded_sequence\n",
    "    - 引数として別途各lengthを与えることで、どこまでがpadではないか判別\n",
    "  - sequenceから作成: torch.nn.utils.rnn.pack_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "# Approach 1:\n",
    "# set up fields\n",
    "TEXT = data.Field(lower=True, batch_first=True, include_lengths=True) # lengthを含める\n",
    "LABEL = data.Field(sequential=True, batch_first=True, pad_token=None, unk_token=None) # vocabularyに反映されてしまうため、unkとpadをNonenに\n",
    "\n",
    "# make splits for data\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'label': <torchtext.data.field.Field object at 0x7f2d9cedb4a8>, 'text': <torchtext.data.field.Field object at 0x7f2d9cedb5c0>}\n",
      "len(train) 25000\n",
      "vars(train[0]) {'label': ['pos'], 'text': ['master', 'cinéaste', 'alain', 'resnais', 'likes', 'to', 'work', 'with', 'those', 'actors', 'who', 'are', 'a', 'part', 'of', 'his', 'family.in', 'this', 'film', 'too', 'we', 'see', \"resnais'\", 'family', 'members', 'like', 'pierre', 'arditi,', 'sabine', 'azema,', 'andré', 'dussolier', 'and', 'fanny', 'ardant', 'dealing', 'with', 'serious', 'themes', 'like', 'death,religion,suicide,love', 'and', 'their', 'overall', 'implications', 'on', 'our', 'daily', 'lives.the', 'formal', 'nature', 'of', 'relationship', 'shared', 'by', 'these', 'people', 'is', 'evident', 'as', 'even', 'friends,', 'they', 'address', 'each', 'other', 'using', 'a', 'formal', 'you.in', '1984,while', 'making', \"l'amour\", 'à', 'mort,resnais', 'dealt', 'with', 'time,memory', 'and', 'space', 'to', 'unravel', 'the', 'mysteries', 'of', 'a', 'fundamental', 'question', 'of', 'human', 'existence', ':is', 'love', 'stronger', 'than', 'death', '?', 'it', 'was', '16', 'years', 'ago', 'in', '1968', 'that', 'resnais', 'made', 'a', 'somewhat', 'similar', 'film', 'je', \"t'aime\", 'je', \"t'aime\", 'which', 'was', 'also', 'about', 'love', 'and', 'memories.message', 'of', 'this', 'film', 'is', 'loud', 'and', 'clear', ':true', 'and', 'deep', 'love', 'can', 'even', 'put', 'science', 'to', 'shame', 'as', 'dead', 'lovers', 'regain', 'their', 'lost', 'lives', 'leaving', 'doctors', 'to', 'care', 'for', 'their', \"reputation.l'amour\", 'à', 'mort', 'is', 'like', 'a', 'game', 'which', 'is', 'not', 'at', 'all', 'didactic.it', 'is', 'a', 'film', 'in', 'which', 'the', 'musical', 'score', 'is', 'in', 'perfect', 'tandem', 'with', 'its', 'images.this', 'is', 'one', 'of', 'the', 'reasons', 'why', 'this', 'film', 'can', 'easily', 'be', 'grasped.']}\n"
     ]
    }
   ],
   "source": [
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))\n",
    "print('vars(train[0])', vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 251639\n",
      "TEXT.vocab.vectors.size() torch.Size([251639, 300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0466  0.2132 -0.0074  ...   0.0091 -0.2099  0.0539\n",
       "          ...             ⋱             ...          \n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 251639x300]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300)) # GloVeのembeddingを使用してvocabularyを作成->各termに対応するembeddingが得られる\n",
    "LABEL.build_vocab(train)\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())\n",
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_iter, 'test': test_iter}\n",
    "dataset_sizes = {'train': len(train), 'test': len(test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   2.0400e+02  1.8900e+02  2.2716e+04\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   4.0000e+00  3.9000e+01  2.8520e+03\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   4.0000e+00  1.5570e+05  4.6610e+04\n",
      "                ...                   ⋱                   ...                \n",
      " 8.2000e+01  5.0000e+00  3.5000e+01  ...   1.0000e+02  5.0000e+00  1.8800e+02\n",
      " 6.2780e+03  9.0000e+00  6.2000e+01  ...   3.3000e+01  4.3700e+02  1.2000e+01\n",
      " 1.3300e+02  2.0000e+00  2.2500e+02  ...   7.3600e+02  1.8321e+04  1.2499e+04\n",
      "[torch.cuda.LongTensor of size 512x500 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    1\n",
      "    1\n",
      "    0\n",
      "    0\n",
      "[torch.cuda.LongTensor of size 512x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.text)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " c nmbb## class NetRNN(nn.Module):\n",
    "    def __init__(self, glove_weight):\n",
    "        super(NetRNN, self).__init__()\n",
    "        self.emb = nn.Embedding(251639, 300)\n",
    "        self.emb.weight.data.copy_(glove_weight) # Gloveの重みをsetする\n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=50, num_layers=1, dropout=0.5)\n",
    "        self.fc = nn.Linear(50, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.emb(x)\n",
    "        if lengths is not None:\n",
    "            lengths = lengths.view(-1).tolist()\n",
    "            packed_emb = nn.utils.rnn.pack_padded_sequence(embed_input, lengths)\n",
    "        \n",
    "        x = x.transpose(0, 1) # N x seq_size x embedding_sizeになっているので、seq_size x N x embedding_size に変換する\n",
    "        # input (seq_len, batch, input_size)\n",
    "        output, (h_n, c_n) = self.lstm(x, hidden)\n",
    "        x = h_n[-1].squeeze(0) # seq_len, batch, hidden_size * num_directions なので[-1]を取る\n",
    "        x = self.fc(x)\n",
    "        return self.sig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetRNN(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "CuDNNError",
     "evalue": "8: b'CUDNN_STATUS_EXECUTION_FAILED'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCuDNNError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-79aaa1a9a631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mcopied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0many_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_descs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0many_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_rnn_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Allocate buffer to hold the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_rnn_descriptor\u001b[0;34m(fn, handle)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdropout_desc_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropout_desc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         fn.dropout_state[dropout_desc_name] = Unserializable(\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropoutDescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     44\u001b[0m     \u001b[0mdropout_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropout_desc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, dropout, seed)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36m_set\u001b[0;34m(self, dropout, seed)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_size_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_ulonglong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         ))\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36mcheck_error\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCuDNNError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCuDNNError\u001b[0m: 8: b'CUDNN_STATUS_EXECUTION_FAILED'"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    \n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.96it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5006\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.02it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5022\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.02it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5031\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.96it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5030\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:27<00:00,  1.80it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.04it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5054\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.03it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5058\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.96it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5079\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.83it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.00it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5080\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.83it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.98it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5087\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.04it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5085\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.02it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5089\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.02it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5084\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.83it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.97it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5086\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:27<00:00,  1.80it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.05it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5085\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.82it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0014 Acc: 0.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:06<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0014 Acc: 0.5086\n",
      "\n",
      "Training complete in 8m 29s\n",
      "Best val Acc: 0.508920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
